{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d12becb",
   "metadata": {},
   "source": [
    "# Portfolio Optimisation Under Market Uncertainty\n",
    "\n",
    "### In this notebook we optimise a portfolio via the Sharpe ratio. We will use exact optimization methods and explore both convex and non-convex problem formulations.\n",
    "\n",
    "We will work through the following sections,\n",
    "\n",
    "**1. Data Collection and Processing**  \n",
    "**2. Maximising the Sharpe Ratio**  \n",
    "**3. Scenario generation: Applying Shocks**  \n",
    "**4. Performance Analysis**  \n",
    "\n",
    "First import the packages which will be used.\n",
    "Data will be accessed via Yahoo finance via ``yfinance``. For convex optimisation ``cvxpy`` will used. For non-convex optimisation we will use ``pyomo``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c420ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import random\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from pyomo.environ import (\n",
    "    ConcreteModel,\n",
    "    Set,\n",
    "    Var,\n",
    "    Constraint,\n",
    "    ConstraintList,\n",
    "    Objective,\n",
    "    SolverFactory,\n",
    "    maximize,\n",
    "    sqrt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d16f6",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Processing\n",
    "We will use real assets and access data from Yahoo Finance. Let's randomly choose 20 assets from S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1fb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to choose assets from a list of tickers\n",
    "def choose_assets(tickers:list, n: int = 5) -> list:\n",
    "    \"\"\"Function to randomly choose n many assets from the S&P 500\"\"\"\n",
    "    # Check if n is greater than the number of tickers\n",
    "    if n > len(tickers):\n",
    "        raise ValueError(\"n cannot be greater than the number of tickers.\")\n",
    "    # Randomly choose n tickers\n",
    "    chosen_tickers = np.random.choice(tickers, size=n, replace=False)\n",
    "    return chosen_tickers.tolist()\n",
    "\n",
    "# Define the list of tickers (S&P 500 companies)\n",
    "# Note: This list is not exhaustive and may not reflect the current S&P 500 companies.\n",
    "my_tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"BRK-B\", \"NVDA\", \"JNJ\", \"V\", \"META\",\n",
    "    \"UNH\", \"XOM\", \"PG\", \"JPM\", \"HD\", \"MA\", \"CVX\", \"LLY\", \"ABBV\", \"PEP\",\n",
    "    \"KO\", \"MRK\", \"T\", \"VZ\", \"NFLX\", \"INTC\", \"CSCO\", \"CMCSA\", \"PFE\", \"NKE\",\n",
    "    \"WMT\", \"DIS\", \"IBM\", \"TMO\", \"MDT\", \"HON\", \"CRM\", \"TXN\", \"QCOM\", \"AVGO\",\n",
    "    \"AMGN\", \"COST\", \"NVS\", \"DHR\", \"LLY\", \"PM\", \"SBUX\", \"LMT\", \"BA\", \"CAT\",\n",
    "    \"GS\", \"BKNG\", \"NOW\", \"ADBE\", \"INTU\", \"ISRG\", \"VRTX\", \"AMD\", \"SNPS\"]\n",
    "\n",
    "# Randomly choose 20 tickers from the list\n",
    "my_assets = choose_assets(tickers=my_tickers, n=20)\n",
    "print(\"Chosen assets:\", my_assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f20576",
   "metadata": {},
   "source": [
    "Now that we have chosen assets, we can collect the data for the chosen assets using yfinance, and calculate the log returns. $$r_t = log(P_t/P_{t-1})$$\n",
    "\n",
    "Converting price data to log returns is common in finance because\n",
    "1. It’s time-additive: \n",
    "2. It's symmetric and handles compounding nicely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a928a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_assets(assets: list,\n",
    "                   start: str = \"2015-01-01\",\n",
    "                   end: str = \"2024-12-31\"):\n",
    "    \"\"\"Function to collect chosen assets\"\"\"\n",
    "    raw_data = yf.download(assets, start=start, end=end, auto_adjust=False)\n",
    "    # Extract only the 'Adj Close' part and clean it up\n",
    "    adj_close = raw_data['Adj Close']\n",
    "    # drop rows with missing data\n",
    "    adj_close = adj_close.dropna()\n",
    "    return adj_close\n",
    "\n",
    "\n",
    "def calculate_log_return(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"converts price data into log returns. r_t = log(P_t/P_{t-1})\"\"\"\n",
    "    return np.log(data / data.shift(1)).dropna()\n",
    "\n",
    "# Collect data for the chosen assets\n",
    "my_data = collect_assets(my_assets)\n",
    "\n",
    "# Calculate log returns\n",
    "my_returns = calculate_log_return(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8895fc",
   "metadata": {},
   "source": [
    "## 2. Maximising the Sharpe Ratio\n",
    "The Sharpe ratio can be defined as,\n",
    "$$\\text{Sharpe ratio}= \\frac{w^T\\mu-r_f}{\\sqrt{w^T\\Sigma w}}$$\n",
    "where \n",
    "- $w$ = vector of portfolio weights\n",
    "- $\\mu$ = expected returns vector\n",
    "- $r_f$ = risk-free rate\n",
    "- $\\Sigma$ = covariance matrix of asset returns\n",
    "\n",
    "> **Note:** For simplicity, the risk-free rate $r_f$ is assumed to be **0** in this analysis.\n",
    "> This means the Sharpe ratio reflects **raw return per unit of volatility**, without adjusting for a baseline risk-free return. This likely does not well represent periods with high interest rates.\n",
    "\n",
    "Here we explore two different modelling approaches:\n",
    "\n",
    "### 2.1. Two Modelling Approaches\n",
    "\n",
    "**2.1.1. Non-Convex Formulation (Exact Sharpe Ratio maximisation using IPOPT)**\n",
    "\n",
    "The Sharpe ratio is defined above as:\n",
    "\n",
    "$$\\text{Sharpe ratio} = \\frac{w^\\top \\mu}{\\sqrt{w^\\top \\Sigma w}},$$\n",
    "\n",
    "is a **non-convex objective** due to the square root in the denominator. While `cvxpy` cannot handle this directly, we can solve it using **nonlinear programming (NLP)** with **IPOPT**, a powerful interior-point solver.\n",
    "\n",
    "**Key characteristics:**\n",
    "- optimises the exact Sharpe ratio\n",
    "- Requires a nonlinear solver (`ipopt`)\n",
    "- Can include real-world constraints (e.g., weight caps)\n",
    "- May converge to local (not global) optima\n",
    "\n",
    "**Used when:** You want to directly optimise risk-adjusted return using realistic market constraints.\n",
    "\n",
    "---\n",
    "\n",
    "**2.1.2. Convex Reformulation (Using CVXPY)**\n",
    "\n",
    "Instead of maximising Sharpe ratio directly, we can **reformulate the problem** into a convex optimization:\n",
    "\n",
    "$$\\text{maximise } w^\\top \\mu \\quad \\text{subject to } w^\\top \\Sigma w \\leq \\sigma^2$$\n",
    "\n",
    "This is a classic **mean-variance optimization**:\n",
    "- Objective: linear in weights\n",
    "- Risk constraint: convex quadratic form\n",
    "- Solved efficiently using `cvxpy` with solvers like `OSQP` or `ECOS`\n",
    "\n",
    "**Key characteristics:**\n",
    "- Fast, reliable, and globally optimal\n",
    "- Requires choosing a maximum allowable portfolio risk ($\\sigma$)\n",
    "- Does not directly maximise Sharpe, but approximates it well\n",
    "\n",
    "**Used when:** You want a stable convex optimization framework and are comfortable selecting a target risk level.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Feature                    | Non-Convex                   | Convex                          |\n",
    "|----------------------------|------------------------------|---------------------------------|\n",
    "| Direct Sharpe maximisation | Yes                        | No (approximate)           |\n",
    "| Convex formulation         | No                         | Yes                        |\n",
    "| Modelling framework        | ``pyomo``                     | ``cvxpy``                      |\n",
    "| Solvers                    | `ipopt` (nonlinear)           | `OSQP`/`ECOS`                  |\n",
    "| Performance                | May be local optimum       | Globally optimal           |\n",
    "| Custom constraints         | Very flexible              | Flexible (if convex)       |\n",
    "| Interpretability           | Moderate (nonlinear form)  | High (explicit trade-offs) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2abc5f",
   "metadata": {},
   "source": [
    "### Sharpe Ratio Optimization Function: `maximise_sharpe_ratio`\n",
    "\n",
    "The `maximise_sharpe_ratio` function is a flexible interface for constructing optimised portfolios using either:\n",
    "\n",
    "- A **non-convex formulation** (directly maximises the Sharpe ratio using IPOPT)\n",
    "- A **convex reformulation** (maximises expected return subject to a fixed risk constraint using CVXPY)\n",
    "\n",
    "The function returns:\n",
    "- Optimal **portfolio weights**\n",
    "- **Expected return** and **portfolio risk** (non-convex only)\n",
    "\n",
    "---\n",
    "\n",
    "### Constraints\n",
    "\n",
    "Constraints are added to represent:\n",
    "\n",
    "- **Fully invested portfolio**: $\\sum{w}=1$,\n",
    "- **No short selling**: $x\\geq 1$.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Features\n",
    "\n",
    "This function is built to support richer financial analysis through:\n",
    "\n",
    "- **Sector-based shocks** to expected returns  \n",
    "- **Covariance scaling** to simulate different volatility regimes  \n",
    "- **Maximum weight constraints** to encourage diversification  \n",
    "\n",
    "---\n",
    "\n",
    "### Parameters\n",
    "\n",
    "| Parameter        | Description                                           |\n",
    "|------------------|-------------------------------------------------------|\n",
    "| `returns`        | Log returns (`pd.DataFrame`) of selected assets       |\n",
    "| `convex`         | `True` to use convex formulation (CVXPY), else IPOPT |\n",
    "| `max_weight`     | Maximum weight allowed per asset (e.g., 0.3)          |\n",
    "| `max_risk`       | Portfolio volatility limit (used in convex mode)      |\n",
    "| `plotting`       | Whether to plot individual asset Sharpe ratios        |\n",
    "| `tickers`        | List of tickers used (needed for sector mapping)      |\n",
    "| `sector_shocks`  | Dictionary of sector-based return shocks              |\n",
    "| `cov_scale`      | Scalar multiplier to apply to the covariance matrix   |\n",
    "\n",
    "---\n",
    "\n",
    "This wrapper function lets you easily compare convex and non-convex formulations under baseline or stressed market assumptions, making it ideal for demonstrating portfolio behavior and robustness in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ce4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions used to maximise the sharpe ratio\n",
    "\n",
    "def get_mean_covariance(returns: pd.DataFrame):\n",
    "    \"\"\"Returns the mean and covariance of log returns data frame\"\"\"\n",
    "    return returns.mean(), returns.cov()\n",
    "\n",
    "def apply_shock(tickers, mu_base, cov_base, sector_shocks, cov_scale=1.0):\n",
    "    \"\"\"Apply a shock scenario to the mean and covariance matrix.\"\"\"\n",
    "\n",
    "    sector_map = {}\n",
    "    for ticker in tickers:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        sector_map[ticker] = info.get('sector', 'Unknown')\n",
    "\n",
    "    mu_shocked = mu_base.copy()\n",
    "    for ticker in tickers:\n",
    "        sector = sector_map.get(ticker, None)\n",
    "        shock = sector_shocks.get(sector, 0)\n",
    "        mu_shocked.loc[ticker] += shock\n",
    "\n",
    "    cov_shocked = cov_base.copy() * cov_scale\n",
    "    return mu_shocked, cov_shocked\n",
    "\n",
    "def maximise_sharpe_ratio_cvxpy(returns: pd.DataFrame,\n",
    "                                mu,\n",
    "                                cov,\n",
    "                                max_weight: float,\n",
    "                                max_risk: float):\n",
    "    \"\"\"Maximise the Sharpe ratio using a convex formulation\"\"\"\n",
    "    n = len(mu)  # number of assets\n",
    "    w = cp.Variable(n)  # asset weights\n",
    "\n",
    "    # Risk target: set max allowed portfolio standard deviation\n",
    "    risk_target = max_risk  # Annualized risk target\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,        # Fully invested\n",
    "        w >= 0,                # No short selling\n",
    "        cp.quad_form(w, cov) <= risk_target**2  # Risk constraint (variance)\n",
    "    ]\n",
    "\n",
    "    # Objective: maximise expected return\n",
    "    objective = cp.Maximize(np.array(mu) @ w)\n",
    "\n",
    "    # Solve the problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    if prob.status != cp.OPTIMAL:\n",
    "        print(\"Problem not solved. Status:\", prob.status)\n",
    "        # resolve with a higher risk target\n",
    "        print(\"Trying again with a higher risk target\")\n",
    "        max_risk += 0.05\n",
    "        if max_risk < 1:\n",
    "            return maximise_sharpe_ratio_cvxpy(returns,\n",
    "                                               mu,\n",
    "                                               cov,\n",
    "                                               max_weight=max_weight,\n",
    "                                               max_risk=max_risk)\n",
    "        else:\n",
    "            raise ValueError(\"Problem not solved. Maximum risk target reached.\")\n",
    "\n",
    "    # Optimal weights\n",
    "    weights = w.value\n",
    "    print(\"maximise sharpe ratio with convex formulation and fixed maximum \"\n",
    "          f\"risk of {max_risk}. \"\n",
    "          f\"Optimal Weights: {', '.join(f'{w:.5f}' for w in weights)}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "def maximise_sharpe_ratio_ipopt(returns: pd.DataFrame,\n",
    "                                mu,\n",
    "                                cov,\n",
    "                                max_weight: float):\n",
    "    \"\"\"Maximise the Sharpe ratio directly using ipopt\"\"\"\n",
    "\n",
    "    cov = {(i, j): cov.iloc[i, j] for i in range(len(cov)) for j in range(len(cov))}\n",
    "    assets = list(range(len(mu)))\n",
    "\n",
    "    # Build the Pyomo model\n",
    "    model = ConcreteModel()\n",
    "\n",
    "    model.assets = Set(initialize=assets)\n",
    "    model.w = Var(model.assets, bounds=(0, 1))  # weights, no shorting\n",
    "\n",
    "    # Constraint: fully invested\n",
    "    model.fully_invested = Constraint(expr=sum(model.w[i] for i in model.assets) == 1)\n",
    "\n",
    "    # add a constraint such that each weight is less than the max weight\n",
    "    if max_weight > 0:\n",
    "        model.max_weight = ConstraintList()\n",
    "        for i in model.assets:\n",
    "            model.max_weight.add(model.w[i] <= 0.3)\n",
    "\n",
    "    # Objective: maximise Sharpe Ratio\n",
    "    def sharpe_ratio(model):\n",
    "        mean_ret = sum(mu.iat[i] * model.w[i] for i in model.assets)\n",
    "        var = sum(\n",
    "            model.w[i] * sum(cov[i, j] * model.w[j] for j in model.assets)\n",
    "            for i in model.assets\n",
    "        )\n",
    "        std_dev = sqrt(var)\n",
    "        return mean_ret / std_dev\n",
    "\n",
    "    model.objective = Objective(rule=sharpe_ratio, sense=maximize)\n",
    "\n",
    "    # Solve the model\n",
    "    solver = SolverFactory(\"ipopt\")\n",
    "    solver.options[\"tol\"] = 1e-8\n",
    "    solver.options[\"print_level\"] = 0\n",
    "    # choose options to suppress solver output\n",
    "    solver.options[\"sb\"] = \"yes\"\n",
    "    solver.solve(model, tee=False)\n",
    "\n",
    "    # Get Results\n",
    "    optimal_weights = np.array([model.w[i].value for i in model.assets])\n",
    "    print(\"maximise sharpe ratio with non-convex formulation. \"\n",
    "          f\"Optimal Weights: {[round(float(w), 5) for w in optimal_weights]}\")\n",
    "    \n",
    "    # Print the resuting risk and return\n",
    "    mean_ret = sum(mu.iat[i] * optimal_weights[i] for i in model.assets)\n",
    "    var = sum(\n",
    "        optimal_weights[i] * sum(cov[i, j] * optimal_weights[j] for j in model.assets)\n",
    "        for i in model.assets\n",
    "    )\n",
    "    std_dev = sqrt(var)\n",
    "    print(f\"Resulting risk: {std_dev}, return: {mean_ret}\")\n",
    "\n",
    "    return optimal_weights, mean_ret, std_dev\n",
    "\n",
    "\n",
    "def maximise_sharpe_ratio(returns: pd.DataFrame, \n",
    "    convex: bool = False,\n",
    "    max_weight: float = 0.0,\n",
    "    max_risk: float = 0.15,\n",
    "    plotting: bool = False,\n",
    "    tickers=None, sector_shocks=None, cov_scale=1.0,\n",
    "):\n",
    "    \"\"\"Given log returns calculate weights such that the sharpe ratio is\n",
    "    maximised\n",
    "\n",
    "    Note the Sharpe ratio is non-convex. We can either:\n",
    "    1. Use a non-convex solver\n",
    "    2. reformulate the problem and use a convex solver:\n",
    "       - We can do this by maximising return for a fixed level of risk\"\"\"\n",
    "    \n",
    "    # Estimate mean returns and covariance\n",
    "    mu, cov = get_mean_covariance(returns)\n",
    "    if sector_shocks is not None:\n",
    "        # Apply shocks to the returns\n",
    "        mu, cov = apply_shock(tickers=tickers, mu_base=mu, cov_base=cov,\n",
    "                              sector_shocks=sector_shocks,\n",
    "                              cov_scale=cov_scale)\n",
    "\n",
    "    if plotting:\n",
    "        individual_returns = mu.copy()\n",
    "        individual_vols = np.sqrt(np.diag(cov))\n",
    "\n",
    "        # Avoid divide-by-zero\n",
    "        individual_sharpes = individual_returns / individual_vols\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        individual_sharpes.sort_values(ascending=False).plot(kind='bar', color='skyblue', edgecolor='k')\n",
    "        plt.title(\"Individual Asset Sharpe Ratios\")\n",
    "        plt.ylabel(\"Sharpe Ratio (Return / Volatility)\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.axhline(0, color='gray', linestyle='--', linewidth=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if not convex:\n",
    "        weights, mean_ret, std_dev = maximise_sharpe_ratio_ipopt(returns,\n",
    "                                                                 mu=mu,\n",
    "                                                                 cov=cov,\n",
    "                                                                 max_weight=max_weight)\n",
    "        return weights, mean_ret, std_dev\n",
    "    else:\n",
    "        weights = maximise_sharpe_ratio_cvxpy(returns,\n",
    "                                              mu=mu,\n",
    "                                              cov=cov,\n",
    "                                              max_weight=max_weight,\n",
    "                                              max_risk=max_risk)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccce19",
   "metadata": {},
   "source": [
    "We can now apply these functions to find portfolio weights under optimal Sharpe ratios. \n",
    "### 2.2 Compare convex and non-convex formulation\n",
    "First let us solve the non-convex problem directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90381bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_weights, base_returns, base_risk = maximise_sharpe_ratio(my_returns, convex=False, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c69f5",
   "metadata": {},
   "source": [
    "We can also solve the convex formulation for the maximal risk calculated via the non-convex problem - this should yield the approximately the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa781dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_weights_convex = maximise_sharpe_ratio(my_returns, convex=True, max_risk=base_risk)\n",
    "# Create a DataFrame to display the weights nicely\n",
    "weights_df = pd.DataFrame({\n",
    "    \"Asset\": my_assets,\n",
    "    \"Non-Convex Weights\": base_weights,\n",
    "    \"Convex Weights\": base_weights_convex\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(weights_df)\n",
    "assert np.allclose(base_weights, base_weights_convex, atol=1e-2), \"Weights from convex and non-convex methods do not match!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7aef9",
   "metadata": {},
   "source": [
    "It may be that a few assets dominate the portfolio. This can be the case depending on how the Sharpe ratios for induvidual assets are distributed (can be seen if option ``plotting=True``). For example if,\n",
    "1. One or two bars are much higher than others: Those assets will dominate dominate and have high weights.\n",
    "2. All bars are close to each other: The optimiser may be unstable and nearly all weights may be ~the same.\n",
    "3. Some bars are negative: Corresponding weights will be zero ( due to optimisation constraint ``w >= 0``).\n",
    "\n",
    "To ensure some level of diversification we can impose a maximum weight to the portfolio. For example, here are the results with a maximum weight of 0.25 applied.\n",
    "\n",
    "If there is a good spread of Sharpe ratio throughout induvidual assets, we should not expect to see large differences in portfolio weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abeceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_weights, base_returns, base_risk = maximise_sharpe_ratio(my_returns, convex=False, max_weight=0.25)\n",
    "\n",
    "# add this to the weights_df\n",
    "weights_df[\"Non-Convex Weights (Max 0.25)\"] = base_weights\n",
    "# Print the DataFrame\n",
    "print(weights_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f558d3",
   "metadata": {},
   "source": [
    "## 3. Scenario Generation: Apply shocks\n",
    "\n",
    "To simulate uncertainty in markets we can apply shocks to asset returns and alter the covariance matrix.\n",
    "\n",
    "here we define shocks per asset class, and apply a simple transformation uniformly upon the covariance matrix. While this behaviour is artificial, it allows us to \n",
    "1. Assess the expected performace of our base portfolio under these shocks,\n",
    "2. Re-caluculate the optimal portfolio in the shocked scenario\n",
    "\n",
    "In the dictionary ``sector_shocks`` we can describe a shock scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_shocks = {\n",
    "    \"Technology\": -0.15,              # Tech crash (e.g., interest rate shock)\n",
    "    \"Energy\": +0.10,                  # Oil price spike\n",
    "    \"Financial Services\": -0.08,      # Banking panic\n",
    "    \"Healthcare\": -0.05,              # Regulatory changes / drug failures\n",
    "    \"Consumer Cyclical\": -0.12,       # Recession hits discretionary spending\n",
    "    \"Consumer Defensive\": +0.02,      # Safe haven during downturn\n",
    "    \"Industrials\": -0.07,             # Supply chain shocks\n",
    "    \"Basic Materials\": -0.10,         # Commodity demand drop\n",
    "    \"Utilities\": +0.03,               # Flight to defensive yield\n",
    "    \"Communication Services\": -0.10,  # Ad revenue collapse or tech overlap\n",
    "    \"Real Estate\": -0.12,             # CRE crash / interest rate stress\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1c6d7",
   "metadata": {},
   "source": [
    "We can also generate sector shocks dynamically. For, we can draw sector shocks from a normal distribution with mean 0 and standard deviation 0.1.\n",
    "\n",
    "That means:\n",
    "* Some sectors will gain expected return\n",
    "* Others will lose\n",
    "\n",
    "We will impose a limit on shocks of +/-0.15 such that markets are not too volatile.\n",
    "\n",
    ">**Note**: This is not a realistic generation of scenarios.\n",
    "\n",
    "Most of the time, the impact will be negative overall for the original portfolio, unless the base portfolio was already tilted toward the positively shocked sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in sector_shocks.keys():\n",
    "    sector_shocks[sector] = random.gauss(0, 0.1)\n",
    "    # force shock between -0.15 and +0.15\n",
    "    sector_shocks[sector] = max(-0.15, min(0.15, sector_shocks[sector]))\n",
    "print(sector_shocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44675588",
   "metadata": {},
   "source": [
    "We can analyse how well our base portfolio behaves under the shock. We can apply a constant scaling factor of 1.1 to the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cov_scale = 1.1\n",
    "shocked_mu, shocked_cov = apply_shock(my_assets, my_returns.mean(), my_returns.cov(), sector_shocks,\n",
    "                                      cov_scale=my_cov_scale)\n",
    "\n",
    "def evaluate_portfolio(w, mu, cov):\n",
    "    \"\"\"Evaluate the portfolio given weights, mean returns, and covariance matrix.\"\"\"\n",
    "    ret = np.dot(w, mu)\n",
    "    vol = np.sqrt(np.dot(w, cov @ w))\n",
    "    return ret, vol, ret / vol\n",
    "\n",
    "shocked_base_returns, _, _ = evaluate_portfolio(base_weights, shocked_mu, shocked_cov)\n",
    "print(f\"Expected returns of the optimised base portfolio under shocks:{shocked_base_returns}\"\n",
    "      f\" vs. {base_returns} without shocks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79624507",
   "metadata": {},
   "source": [
    "It is most likely that the portfolio performed worse. In these cases it is interesting to compare which asset weights result in optimal Sharpe Ratio under the schocked scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6138d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_weights, shock_returns, shock_risk = maximise_sharpe_ratio(my_returns, convex=False, max_weight=0.25,\n",
    "                                   tickers=my_assets,\n",
    "                                   sector_shocks=sector_shocks,\n",
    "                                   cov_scale=my_cov_scale,\n",
    "                                   plotting=True)\n",
    "\n",
    "print(\"Base weights:\", base_weights)\n",
    "print(\"Optimised shock scenario weights:\", shock_weights)\n",
    "print(\"Base risk:\", base_risk)\n",
    "print(\"Optimised shock scenario risk:\", shock_risk)\n",
    "print(\"Base returns:\", base_returns)\n",
    "print(\"Optimised shock scenario returns:\", shock_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df229b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n_scenarios of shocks\n",
    "n_scenarios = 10\n",
    "scenarios = []\n",
    "for _ in range(n_scenarios):\n",
    "    scenario = {}\n",
    "    for sector in sector_shocks.keys():\n",
    "        scenario[sector] = random.gauss(0, 0.1)\n",
    "        # force shock between -0.15 and +0.15\n",
    "        scenario[sector] = max(-0.15, min(0.15, scenario[sector]))\n",
    "    scenarios.append(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358f8dc",
   "metadata": {},
   "source": [
    "Robust optimisation: First take an approach where we optimise each scenario separately and take the robust portfolio to consist of assets where weights are determined by averages of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the portfolio such that it is robust to the shocks\n",
    "robust_weights = []\n",
    "for scenario in scenarios:\n",
    "    weights, _, _ = maximise_sharpe_ratio(my_returns, convex=False, max_weight=0.25,\n",
    "                                          tickers=my_assets,\n",
    "                                          sector_shocks=scenario,\n",
    "                                          cov_scale=my_cov_scale)\n",
    "    robust_weights.append(weights)\n",
    "\n",
    "# Calculate the average weights across all scenarios\n",
    "robust_weights = np.mean(robust_weights, axis=0)\n",
    "# check if the weights sum to 1\n",
    "assert np.isclose(np.sum(robust_weights), 1), \"Robust weights do not sum to 1.\"\n",
    "print(\"Robust weights:\", robust_weights)\n",
    "# Print the DataFrame with robust weights\n",
    "weights_df[\"Robust Weights\"] = robust_weights\n",
    "print(weights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The sum of the robust weights is: {np.sum(robust_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57e046",
   "metadata": {},
   "source": [
    "We can run a Monte Carlo simulation to evaluate the robustness of the portfolio. For robust metrics a high number of simulations should be run (~10,000). Here, we keep the number small to limit run times but high enough to generate clean visuals. To facilitate higher run numbers, the functions used can be vectorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Use a Monte Carlo simulation to evaluate the robustness of the portfolio\n",
    "n_simulations = 100\n",
    "simulated_returns = []\n",
    "for _ in tqdm(range(n_simulations), desc=\"Simulating\"):\n",
    "    # Generate random shocks for each sector\n",
    "    random_shocks = {sector: random.gauss(0, 0.1) for sector in sector_shocks.keys()}\n",
    "    # Apply the shocks to the mean and covariance\n",
    "    sim_mu, sim_cov = apply_shock(my_assets, my_returns.mean(), my_returns.cov(), random_shocks,\n",
    "                                  cov_scale=my_cov_scale)\n",
    "    # Evaluate the portfolio\n",
    "    ret, vol, sharpe = evaluate_portfolio(robust_weights, sim_mu, sim_cov)\n",
    "    simulated_returns.append((ret, vol, sharpe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "simulated_df = pd.DataFrame(simulated_returns, columns=[\"Return\", \"Volatility\", \"Sharpe\"])\n",
    "# Calculate statistics\n",
    "mean_return = simulated_df[\"Return\"].mean()\n",
    "mean_volatility = simulated_df[\"Volatility\"].mean()\n",
    "mean_sharpe = simulated_df[\"Sharpe\"].mean()\n",
    "# Calculate the 95% confidence intervals\n",
    "lower_bound = simulated_df[\"Return\"].quantile(0.025)\n",
    "upper_bound = simulated_df[\"Return\"].quantile(0.975)\n",
    "# Print the results\n",
    "print(f\"Mean Return: {mean_return:.4f}\")\n",
    "print(f\"Mean Volatility: {mean_volatility:.4f}\")\n",
    "print(f\"Mean Sharpe Ratio: {mean_sharpe:.4f}\")\n",
    "print(f\"95% Confidence Interval for Return: ({lower_bound:.4f}, {upper_bound:.4f})\")\n",
    "# Plot the distribution of simulated returns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(simulated_df[\"Return\"], bins=30, color='skyblue', edgecolor='k', alpha=0.7)\n",
    "plt.axvline(mean_return, color='red', linestyle='dashed', linewidth=1, label='Mean Return')\n",
    "plt.axvline(lower_bound, color='green', linestyle='dashed', linewidth=1, label='95% CI Lower Bound')\n",
    "plt.axvline(upper_bound, color='orange', linestyle='dashed', linewidth=1, label='95% CI Upper Bound')\n",
    "plt.title(\"Distribution of Simulated Returns\")\n",
    "plt.xlabel(\"Return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f96dc5",
   "metadata": {},
   "source": [
    "In this Monte Carlo simulation, we modeled the distribution of portfolio returns based on the Sharpe ratio optimization approach. The histogram provides a visual representation of the simulated returns, offering insight into the portfolio's risk and return characteristics.\n",
    "\n",
    "Key findings include:\n",
    "\n",
    "* Mean Return: The red dashed line indicates the expected mean return of the portfolio. This is the return we would anticipate under typical conditions.\n",
    "\n",
    "* 95% Confidence Interval: The green and orange dashed lines denote the 95% confidence interval bounds, capturing the range within which we expect most simulated returns to fall. This helps quantify the uncertainty associated with the portfolio's return potential.\n",
    "\n",
    "* Risk Profile: The distribution of returns reveals a fat left tail, suggesting a higher frequency of large negative returns compared to what would be expected under a normal distribution. This indicates the presence of increased downside risk in the portfolio. While most of the simulated returns are close to the mean, the possibility of extreme losses exists, highlighting the importance of risk management strategies to mitigate such potential negative outcomes.\n",
    "\n",
    "* Non-normal Distribution: The presence of a fat left tail also suggests that the return distribution is not perfectly normal, with a higher probability of significant negative returns. This is a crucial consideration for assessing the robustness of the portfolio and ensuring that risk measures such as the Sharpe ratio accurately reflect the portfolio's true risk profile."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python312venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
